{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b01b3b-b9cf-4447-9259-93ed9bcdefb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0058786-e995-4ce7-b7de-cd7ba09af643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "194fd2c3-001f-4949-8a91-a9ee91c87809",
   "metadata": {},
   "source": [
    "# **Chapter 4**\n",
    "## *Persisting Time Series Data to Files*, \n",
    "\n",
    "This chapter covers different options and use cases to store time series data for later retrieval. The techniques will cover various methods and file types, whether on-premises or in the cloud. In addition, this chapter covers serialization, compression, overwriting, or appending to files. \n",
    "\n",
    "We will cover the following recipes on how to ingest data into a pandas DataFrame:\n",
    "* Time series data serialization with pickle\n",
    "* Writing to CSV and other delimited files\n",
    "* Writing data to an Excel file\n",
    "* Storing data to a private S3 bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b826dd84-6964-4512-90de-50e8d23b5868",
   "metadata": {},
   "source": [
    "# Recipe 1: Serializing time series data with pickle\n",
    "* This recipe explains the concept of data serialization \n",
    "* Demonstrate how pickling works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b6c194-3b9e-410e-ab5b-40c62585d799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15656c7b-e2e7-4a6f-a1e5-4dd6a4b127b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5badf72-9648-4a0d-9d4f-bc96b2f8ab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \\\n",
    "Path('../../datasets/Ch4/time_series_covid19_confirmed_global.csv')\n",
    "df = pd.read_csv(file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac7252d-aa4b-4d4a-b157-b9eaf6c47173",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a34737a-9af9-486a-a65a-b7a15f8fdc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data where Country is United States\n",
    "df_usa = df[df['Country/Region'] == 'US']\n",
    "# filter columns from June to end of September\n",
    "df_usa_summer = df_usa.loc[:, '6/1/21':'9/30/21']\n",
    "# pivot the data \n",
    "df_usa_summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97c7e8e-7324-4301-aa32-d71bd1ceb7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpivot using pd.melt()\n",
    "df_usa_summer_unpivoted = \\\n",
    "    pd.melt(df_usa_summer,\n",
    "            value_vars=df_usa_summer.columns,\n",
    "            value_name='cases',\n",
    "            var_name='date').set_index('date')\n",
    "\n",
    "\n",
    "df_usa_summer_unpivoted.index = \\\n",
    "    pd.to_datetime(df_usa_summer_unpivoted.index, format=\"%m/%d/%y\")\n",
    "\n",
    "df_usa_summer_unpivoted.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bb6eb9-a676-49a1-af78-510d59990995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_usa_summer_unpivoted.index = \\\n",
    "# pd.to_datetime(df_usa_summer_unpivoted.index, format=\"%m/%d/%y\")\n",
    "\n",
    "# df_usa_summer_unpivoted.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7483557b-191d-47d4-909a-d2d98eada98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_usa_summer_unpivoted.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef960f-d0cf-4180-b10f-d698bd393a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output =\\\n",
    "Path('../../datasets/Ch4/covid_usa_summer_2021.pkl')\n",
    "\n",
    "df_usa_summer_unpivoted.to_pickle(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e93ae0-7435-41cd-9e4e-d6136c6cf82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unpickled_df = pd.read_pickle(output)\n",
    "unpickled_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b1cdc8-efcd-453b-8e74-4ef9fe3ef565",
   "metadata": {},
   "source": [
    "## Writing a Pickle file using the Pickle library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f0c22e-141f-4808-b3b3-f1eba0743ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6ee014-c730-4c91-adf3-659a27eaa09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \\\n",
    "Path('../../datasets/Ch4/covid_usa_summer_2021_v2.pkl')\n",
    "\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(df_usa_summer_unpivoted, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4ec6bb-6301-466a-bb4f-182c587775f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, \"rb\") as file:\n",
    "    df = pickle.load(file)\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1ccdd1-a5a6-4913-8654-b2f0b5b88308",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output, \"wb\") as file:\n",
    "    pickle.dump(df_usa_summer_unpivoted, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75206b5-1216-43ed-bb77-d770f4288125",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output, \"rb\") as file:\n",
    "    df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb7aaf9-8b72-4384-9353-f117890d57e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_output =\\\n",
    "Path('../../datasets/Ch4/covid_usa_summer_2021.zip')\n",
    "\n",
    "# write the Dataframe\n",
    "df_usa_summer_unpivoted.to_pickle(zip_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31c5092-a26e-4e91-a806-fc253d07218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the DataFrame\n",
    "pd.read_pickle(zip_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e411774-dbf3-4cbf-9e5f-66f426781c72",
   "metadata": {},
   "source": [
    "#### Check seriealization protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0e6ba7-3891-4f2f-a1f6-9fe20582f7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.HIGHEST_PROTOCOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9404b3d-c334-43b9-82dd-dae3b89b6c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output, \"wb\") as file:\n",
    "    pickle.dump(df_usa_summer_unpivoted,\n",
    "                file,\n",
    "                pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# this is equivalent to the following\n",
    "with open(output, \"wb\") as file:\n",
    "    pickle.dump(df_usa_summer_unpivoted,\n",
    "                file,\n",
    "                5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2138370c-b519-4558-a6b2-4d7eb9e98471",
   "metadata": {},
   "source": [
    "## There is more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04581924-19bf-4c8d-8292-0729df0588e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def covid_by_country(file, days, country):\n",
    "    ts = pd.read_csv(file)\n",
    "    ts = ts[ts['Country/Region'] == country]\n",
    "    final = ts.iloc[:, -days:].sum()\n",
    "    final.index = pd.to_datetime(final.index, \n",
    "                                format=\"%m/%d/%y\")\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280659da-d401-4eb1-b239-e572af3ac6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \\\n",
    "Path('../../datasets/Ch4/time_series_covid19_confirmed_global.csv')\n",
    "\n",
    "us_past_120_days = covid_by_country(file, 200, 'US')\n",
    "us_past_120_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6d1b99-0012-4dbe-87b3-0392520d5f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b4a42e-c5fd-4e0c-a758-f6f120d6141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_example = \\\n",
    "us_past_120_days.plot(title=f'COVID confirmed case for US',\n",
    "                xlabel='Date',\n",
    "                ylabel='Number of Confirmed Cases');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbb3e05-9c6c-4ad1-a3aa-b7b8b6c953b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_example.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207e8916-42eb-4d2f-9e0d-0a2abab7f28d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07cd645-cb80-49ed-bfd0-9e84ef145f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "metadata = {\n",
    "    'date': datetime.now(),\n",
    "    'data': '''\n",
    "        COVID-19 Data Repository by the \n",
    "        Center for Systems Science and Engineering (CSSE) \n",
    "        at Johns Hopkins University'\n",
    "        ''',\n",
    "    'author': 'Tarek Atwan',\n",
    "    'version': 1.0,\n",
    "    'function': covid_by_country,\n",
    "    'example_df' : us_past_120_days,\n",
    "    'example_plot': plot_example\n",
    "}\n",
    "\n",
    "file_path = Path('../../datasets/Ch4/covid_data.pkl')\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(metadata, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aef365-0be4-4766-9bdb-98f0be6eaa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'rb') as file:\n",
    "    content = pickle.load(file)\n",
    "content.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c1432-0352-4629-aab8-92fbd14296b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path =\\\n",
    "Path('../../datasets/Ch4/time_series_covid19_confirmed_global.csv')\n",
    "\n",
    "loaded_func = content['function']\n",
    "loaded_func(file_path, 120, 'China').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40683457-427d-4603-8b8d-0a2571859005",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_df = content['example_df']\n",
    "loaded_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d20072b-3b1e-40a2-96c5-4638bc0c085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_plot = content['example_plot']\n",
    "loaded_plot.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8add49-08d3-4146-bbb1-9d0862ed02c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.HIGHEST_PROTOCOL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfd144c-a97f-409f-a707-d014eef41a52",
   "metadata": {},
   "source": [
    "# Recipe 2: Writing as CSV and other delimited files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3b484a-2797-42b1-89ea-2747a6cc221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea95f4fd-961f-4b79-b5c7-f9c68c770dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "filepath = Path('../../datasets/Ch4/movieboxoffice.csv')\n",
    "\n",
    "movies = pd.read_csv(filepath,\n",
    "                 header=0,\n",
    "                 parse_dates=[0],\n",
    "                 index_col=0,\n",
    "                 usecols=['Date',\n",
    "                          'Daily'],\n",
    "                date_format=\"%d-%b-%y\")\n",
    "movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fc5436-8c2f-434e-ba0e-8347c676f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06c88f2-25ec-4d42-a8b7-469f4bfc41fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Path('../../datasets/Ch4/df_movies.csv')\n",
    "movies.to_csv(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d2d5a3-5dda-432c-a472-c221fb9551c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Path('../../datasets/Ch4/piped_df_movies.csv')\n",
    "movies.to_csv(output, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2a6260-72d5-4f4c-92a0-325c693cc1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(output, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0189ccf5-0646-4180-94da-a45ed484ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a4d644-13af-4cbd-930b-0385c289cf8e",
   "metadata": {},
   "source": [
    "\n",
    "### Special cases when using `.to_csv()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e50c98-4bf5-4192-8fd2-7945455be4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "person = pd.DataFrame({\n",
    "     'name': ['Bond, James', 'Smith, James', 'Bacon, Kevin'],\n",
    "     'location': ['Los Angeles, CA', 'Phoenix, AZ', 'New York, NY'],\n",
    "     'net_worth': [10000, 9000, 8000]\n",
    "    })\n",
    "\n",
    "print(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ed15fb-f77d-4c78-9c67-366c58d263bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "person.to_csv('person_a.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd197d4a-92de-4b39-abda-9698af8ad9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc583139-9bd7-49c6-bf47-487506a641d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d3cd79-700b-4f2a-a0b0-36b0f95cedf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('person_a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba330bb2-9ec3-4165-a143-d48b78c8ca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "person.to_csv('person_b.csv', \n",
    "               index=False, \n",
    "               quoting=csv.QUOTE_ALL)\n",
    "\n",
    "person.to_csv('person_c.csv', \n",
    "               index=False, \n",
    "               quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "person.to_csv('person_d.csv', \n",
    "               index=False, \n",
    "               quoting= csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "person.to_csv('person_e.csv', \n",
    "               index=False, \n",
    "               quoting= csv.QUOTE_NONE, escapechar='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91db8aa7-95b5-4219-a130-465d8dca583e",
   "metadata": {},
   "source": [
    "# Recipe 3: Writing data to an Excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b348ab72-2d41-4318-a124-9a877f20cec4",
   "metadata": {},
   "source": [
    "In the *Reading data from an Excel file* recipe in **Chapter 2**, *Reading Time Series Data from Files*, you were instructed to install `openpyxl` for the read engine. For this recipe, you will be using the same openpyxl for the write engine.  \n",
    "\n",
    "* To install `openpyxl` using `conda`, run the following:\n",
    "\n",
    "```\n",
    "conda install openpyxl\n",
    "```\n",
    "* You can also use `pip`:\n",
    "\n",
    "```\n",
    "pip install openpyxl\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29eba17-2bdc-4788-8b6c-31ded2b0b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "# import xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b7cd98-423f-432e-8506-c666c6ba3cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(openpyxl.__version__)\n",
    "# print(xlsxwriter.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f048b630-f24d-485e-a0de-f51e515b3482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing for the recipe\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "filepath = Path('../../datasets/Ch4/movieboxoffice.csv')\n",
    "\n",
    "movies = pd.read_csv(filepath,\n",
    "                 header=0,\n",
    "                 parse_dates=[0],\n",
    "                 index_col=0,\n",
    "                 usecols=['Date',\n",
    "                          'Daily'],\n",
    "                date_format=\"%d-%b-%y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b486e05e-7d4b-49e2-bf8d-a190bbdd717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = \\\n",
    "Path('../../datasets/Ch4/daily_boxoffice.xlsx')\n",
    "\n",
    "movies.to_excel(output,\n",
    "               sheet_name='movies_data',\n",
    "               engine='openpyxl', # default engine for xlsx files\n",
    "               index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae58dc1c-de1e-43f2-8d4d-a38f35830ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b62279-0eae-43ad-bfcb-824120a0ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_excel(output).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213819cf-e755-4cdd-a3ee-7ac14bccc874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ff7e2a-8b58-4188-a59b-08d377cde780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl.styles import NamedStyle\n",
    "\n",
    "date_style = NamedStyle(name='datetime', number_format='DD/MM/YYYY HH:MM:MM')\n",
    "ws['A1'].style = date_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749a4e46-31f2-4821-88f7-3526e0a05921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install conda-forge::xlsxwriter -y\n",
    "\n",
    "# this is a fix for the OpenPyXL issue\n",
    "date_col = 'Date'\n",
    "with pd.ExcelWriter(output,  \n",
    "                    engine='openpyxl',\n",
    "                    mode='a',\n",
    "                    if_sheet_exists='replace') as writer:\n",
    "    movies.to_excel(writer, sheet_name='movies_fixed_dates', index=True)\n",
    "   \n",
    "    worksheet = writer.sheets['movies_fixed_dates']\n",
    "\n",
    "    for col in worksheet.iter_cols():\n",
    "        header = col[0] # capture headers\n",
    "        if header.value == date_col:\n",
    "            for row in range(2, # skip first row\n",
    "                             worksheet.max_row+1):\n",
    "                    worksheet.cell(\n",
    "                        row, \n",
    "                        header.column\n",
    "                                  ).number_format='MM-DD-YYYY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f716d04-7a03-4dba-b46c-2825bdcd4f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.ExcelWriter(output,  \n",
    "#                     engine='openpyxl',\n",
    "#                     mode='a',\n",
    "#                     date_format='%m-%d-%Y',\n",
    "#                     # datetime_format='MM-DD-YYYY',\n",
    "#                     if_sheet_exists='replace') as writer:\n",
    "    \n",
    "#     # wr = writer\n",
    "    \n",
    "#     movies.to_excel(writer, sheet_name='movies_fixed_dates', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c703bf74-ba6e-4114-a66e-c5e6f8243b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # wr.datetime_format\n",
    "# # pd.ExcelWriter.engine\n",
    "# date_format = 'MM-DD-YYYY'\n",
    "\n",
    "# with pd.ExcelWriter(output,  \n",
    "#                     engine='openpyxl',\n",
    "#                     date_format = 'MM-DD-YYYY',\n",
    "#                    datetime_format = 'MM-DD-YYYY') as writer:\n",
    "#     # writer.datetime_format = date_format\n",
    "#     movies.to_excel(writer, sheet_name='movies_fixed_dates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906e38bb-dcd5-4eb7-8df5-ac65913b4943",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(output,  \n",
    "                    engine='openpyxl',\n",
    "                    mode='a',\n",
    "                   if_sheet_exists='new') as writer:\n",
    " \n",
    "    movies.to_excel(writer, sheet_name='movies_fixed_dates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51755f18-ad96-4e87-bd0f-2ee40d48c008",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['Month'] = movies.index.month_name()\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b603c287-9c12-42b2-973f-741cfdc1cb16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78344804-85e4-4e13-b06e-26027f983d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl.utils.dataframe import dataframe_to_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcbeafc-8074-4371-90a0-4e6b8d86b838",
   "metadata": {},
   "source": [
    "### Split the DataFrame into multiple sheets by Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceb46f4-972b-4388-8b17-2992ac652e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sheet_date_format(sheet_name, writer, date_col):\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "    \n",
    "    for col in worksheet.iter_cols():\n",
    "        header = col[0] \n",
    "        if header.value == date_col:\n",
    "            for row in range(2, worksheet.max_row+1):\n",
    "                    worksheet.cell(\n",
    "                        row, \n",
    "                        header.column).number_format='MM-DD-YYYY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b26d38b-f442-4183-a218-294ad0eaa9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['Month'] = movies.index.month_name()\n",
    "\n",
    "output = Path('../../datasets/Ch4/boxoffice_by_month.xlsx')\n",
    "with pd.ExcelWriter(output,\n",
    "                    engine='openpyxl') as writer:\n",
    "    for month, data in movies.groupby('Month'):\n",
    "        data.to_excel(writer, sheet_name=month)\n",
    "        sheet_date_format(month, writer, date_col='Date')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04e4669-e0ba-4b8a-9fb6-b6fb9502ceca",
   "metadata": {},
   "source": [
    "# Recipe 4: Storing Data to S3\n",
    "In this recipe, you will explore writing to AWS S3 using pandas and another approach using the AWS Python SDK. The pandas approach can be used to write files to other cloud storage locations, such as Azure or Google Cloud.\n",
    "\n",
    "In the *Reading data from a URL* recipe in **Chapter 2**, *Reading Time Series Data from Files*, you were instructed to install boto3 and s3fs in order to read from AWS S3 buckets. In this recipe, you will be leveraging the same libraries.\n",
    "\n",
    "* To install using pip, you can use this:\n",
    "\n",
    "```\n",
    "pip install boto3 s3fs\n",
    "```\n",
    "\n",
    "* To install using conda, you can use this:\n",
    "\n",
    "```\n",
    "conda install boto3 s3fs -y\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1525285-f3af-4d2b-8b0e-46df68705e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c conda-forge azure-storage-blob azure-identity -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c9b015-c826-4a4e-b57d-dce7d17dda95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c conda-forge adlfs gcsfs -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565b27aa-69ef-4121-b99b-3d34a95ed0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install boto3 s3fs google-cloud-storage gcsfs -y\n",
    "# from google.cloud import storage\n",
    "# storage_client = storage.Client(project=GCP_PROJECTID, credentials=GCP_API_KEY)\n",
    "# bucket = storage_client.bucket('tscookbook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a734cc-f8e0-4c27-aea4-777fd06235b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('cloud.cfg')\n",
    "\n",
    "AWS_ACCESS_KEY = config['AWS']['aws_access_key']\n",
    "AWS_SECRET_KEY = config['AWS']['aws_secret_key']\n",
    "AZURE_ACCOUNT_KEY = config['AZURE']['storage_account_key']\n",
    "GCP_KEY_FILE = config['GCP']['key_file_path']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417785e4-e0ca-4709-8cba-02f2ab1c862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "source = \"../../datasets/Ch4/boxoffice_by_month.xlsx\"\n",
    "movies = pd.concat(pd.read_excel(source,\n",
    "             sheet_name=None,\n",
    "             index_col='Date',\n",
    "             parse_dates=True)).droplevel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8812b45e-8755-493a-833f-f8b0130eb726",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies.head())\n",
    "movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056b42f4-ceac-4829-a8b9-3b5de8fc2c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from google.cloud import storage\n",
    "\n",
    "# # Replace with the path to your service account key\n",
    "# key_file_path = 'valiant-cycle-431419-h2-c5bc48019533.json'\n",
    "\n",
    "# # Authenticate using the service account key\n",
    "# storage_client = storage.Client.from_service_account_json(key_file_path)\n",
    "\n",
    "# # Rest of your code to read the CSV\n",
    "# bucket_name = 'tscookbook'\n",
    "# file_path = 'my_movies.csv'\n",
    "\n",
    "# blob = storage_client.bucket(bucket_name).blob(file_path)\n",
    "# blob.download_to_filename('temp.csv')\n",
    "\n",
    "# df = pd.read_csv('temp.csv')\n",
    "\n",
    "# # Delete the temporary file\n",
    "# import os\n",
    "# os.remove('temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd57a54b-27fc-4efc-adb7-e9b26f83500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to Amazon S3\n",
    "\n",
    "movies.to_csv('s3://tscookbook-private/movies_s3.csv',\n",
    "               storage_options={\n",
    "                   'key': AWS_ACCESS_KEY,\n",
    "                   'secret': AWS_SECRET_KEY\n",
    "               })\n",
    "\n",
    "movies.to_excel('s3://tscookbook-private/movies_s3.xlsx',\n",
    "               storage_options={\n",
    "                   'key': AWS_ACCESS_KEY,\n",
    "                   'secret': AWS_SECRET_KEY\n",
    "               })\n",
    "\n",
    "# Writing to Google Cloud Storage \n",
    "\n",
    "\n",
    "movies.to_csv('gs://tscookbook/movies_gs.csv',\n",
    "               storage_options={'token': GCP_KEY_FILE})\n",
    "\n",
    "movies.to_excel('gs://tscookbook/movies_gs.xlsx',\n",
    "               storage_options={'token': GCP_KEY_FILE})\n",
    "\n",
    "# Writing to Azure Blob Storage \n",
    "\n",
    "movies.to_csv(\"abfs://objects@tscookbook.dfs.core.windows.net/movies_abfs.csv\",\n",
    "             storage_options={\n",
    "                 'account_key': AZURE_ACCOUNT_KEY\n",
    "             })\n",
    "\n",
    "movies.to_csv(\"az://objects@tscookbook.dfs.core.windows.net/movies_az.csv\",\n",
    "             storage_options={\n",
    "                 'account_key': AZURE_ACCOUNT_KEY\n",
    "             })\n",
    "\n",
    "movies.to_csv(\"az://objects/movies_az2.csv\",\n",
    "             storage_options={\n",
    "                 'account_name': \"tscookbook\",\n",
    "                 'account_key': AZURE_ACCOUNT_KEY\n",
    "             })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d1b4e2-656e-4ab1-b1c3-48cd5b984bec",
   "metadata": {},
   "source": [
    "## There is more\n",
    "### Using `boto3`, `google.cloud`, and `azure.storage.blob`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c884cf44-4a5e-46ed-a1c0-3e94117acba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boto3\n",
    "# from io import StringIO\n",
    "\n",
    "# bucket = \"tscookbook-private\"\n",
    "# s3_client = boto3.resource(\"s3\",\n",
    "#             aws_access_key_id = AWS_ACCESS_KEY,\n",
    "#             aws_secret_access_key = AWS_SECRET_KEY)\n",
    "\n",
    "# with StringIO() as in_memory_buffer:\n",
    "#     movies.to_csv(in_memory_buffer)\n",
    "#     response = s3_client.Object(bucket, 'new_df.csv').put(Body=in_memory_buffer.getvalue())\n",
    "#     status = response['ResponseMetadata']['HTTPStatusCode']\n",
    "#     if status == 200:\n",
    "#         print('Successful Write')\n",
    "#     else:\n",
    "#         print('Unsucessful Write - ', status)\n",
    "\n",
    "data = movies.to_csv(encoding='utf-8', index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9388b90-4a10-46fe-adcd-a2f78f1b699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "bucket = \"tscookbook-private\"\n",
    "\n",
    "# Using the Resource API\n",
    "s3_resource = boto3.resource(\"s3\",\n",
    "            aws_access_key_id = AWS_ACCESS_KEY,\n",
    "            aws_secret_access_key = AWS_SECRET_KEY)\n",
    "\n",
    "s3_resource.Object(bucket, 'movies_boto3_resourceapi.csv').put(Body=data)\n",
    "\n",
    "\n",
    "# Using the Client API\n",
    "s3_client = boto3.client(\"s3\",\n",
    "            aws_access_key_id = AWS_ACCESS_KEY,\n",
    "            aws_secret_access_key = AWS_SECRET_KEY)\n",
    "\n",
    "s3_client.put_object(Body=data, Bucket=bucket, Key='movies_boto3_clientapi.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebed984-0147-492f-8379-a094bc676def",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "# Authenticate using the service account key\n",
    "storage_client = storage.Client.from_service_account_json(GCP_KEY_FILE)\n",
    "\n",
    "bucket_name = 'tscookbook'\n",
    "file_path = 'movies_gsapi.csv'\n",
    "\n",
    "blob = storage_client.bucket(bucket_name).blob(file_path)\n",
    "\n",
    "blob.upload_from_string(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77453a9e-29a8-4da1-9c7d-b8974df4b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(storage_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d7fcbd-b94e-4ca9-8692-a3212d3303af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "blob_service_client = BlobServiceClient(\n",
    "        account_url=\"https://tscookbook.blob.core.windows.net\",\n",
    "        credential=AZURE_ACCOUNT_KEY)\n",
    "\n",
    "blob_client = blob_service_client.get_blob_client(\n",
    "    container='objects',\n",
    "    blob='movies_blobapi.csv')\n",
    "\n",
    "blob_client.upload_blob(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf9d9c7-b0a6-425d-a186-4138f408e0bf",
   "metadata": {},
   "source": [
    "# Recipe 5: Writing Large Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8027847d-da8c-4c0e-9d47-3f8333fd778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install pytables -y\n",
    "# ! conda install -c conda-forge fastavro -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08174f85-2995-41e2-b34c-c9aed04aa767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "file_path = Path('../../datasets/Ch2/yellow_tripdata_2023-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc1afd31-065a-43f0-b383-2fe7a757e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(file_path, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46f3acf0-6c7e-4583-bfda-26a0dbc8ad03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3066766 entries, 0 to 3066765\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               int64         \n",
      " 1   tpep_pickup_datetime   datetime64[us]\n",
      " 2   tpep_dropoff_datetime  datetime64[us]\n",
      " 3   passenger_count        float64       \n",
      " 4   trip_distance          float64       \n",
      " 5   RatecodeID             float64       \n",
      " 6   store_and_fwd_flag     object        \n",
      " 7   PULocationID           int64         \n",
      " 8   DOLocationID           int64         \n",
      " 9   payment_type           int64         \n",
      " 10  fare_amount            float64       \n",
      " 11  extra                  float64       \n",
      " 12  mta_tax                float64       \n",
      " 13  tip_amount             float64       \n",
      " 14  tolls_amount           float64       \n",
      " 15  improvement_surcharge  float64       \n",
      " 16  total_amount           float64       \n",
      " 17  congestion_surcharge   float64       \n",
      " 18  airport_fee            float64       \n",
      "dtypes: datetime64[us](2), float64(12), int64(4), object(1)\n",
      "memory usage: 444.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37ce40e4-5bc8-430c-b00d-351c10a94dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def size_in_mb(file):\n",
    "    size_bytes = os.path.getsize(file)\n",
    "    size_m = size_bytes / (1024**2)\n",
    "    return round(size_m,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "070157fc-3974-4251-871c-fefcac0ca401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.61 s, sys: 488 ms, total: 5.1 s\n",
      "Wall time: 5.15 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1165.21"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.to_json('formats/yellow_tripdata.json', orient='records')\n",
    "size_in_mb('formats/yellow_tripdata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e4e200e-c62b-4fb8-925d-659dae05f632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.6 s, sys: 451 ms, total: 17.1 s\n",
      "Wall time: 17.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "307.04"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.to_csv('formats/yellow_tripdata.csv', index=False)\n",
    "size_in_mb('formats/yellow_tripdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bad8efa0-c45f-4aa7-b497-52936ac6868c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 966 ms, sys: 66.3 ms, total: 1.03 s\n",
      "Wall time: 976 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "319.94"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.to_orc('formats/yellow_tripdata_uncompressed.orc', \n",
    "          engine_kwargs={'compression':'uncompressed'})\n",
    "size_in_mb('formats/yellow_tripdata_uncompressed.orc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "013bb929-ceed-489a-bb3c-67f74e7de7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 973 ms, sys: 52.6 ms, total: 1.03 s\n",
      "Wall time: 1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "319.65"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.to_orc('formats/yellow_tripdata_lz4.orc', \n",
    "          engine_kwargs={'compression':'lz4'})\n",
    "size_in_mb('formats/yellow_tripdata_lz4.orc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d630d47c-c2e6-4412-8d50-46582a3119ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.42 s, sys: 20.1 ms, total: 1.44 s\n",
      "Wall time: 1.37 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "53.58"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.to_orc('formats/yellow_tripdata_zstd.orc', \n",
    "          engine_kwargs={'compression':'zstd'})\n",
    "size_in_mb('formats/yellow_tripdata_zstd.orc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "751421ba-25f7-4a59-a8d5-fcdc984ba13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 142 ms, sys: 63 ms, total: 205 ms\n",
      "Wall time: 268 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "435.84"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.to_feather('formats/yellow_tripdata_uncompressed.feather', compression='uncompressed')\n",
    "size_in_mb('formats/yellow_tripdata_uncompressed.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd35e672-4142-4c61-9556-002eb9cb5c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 611 ms, sys: 29.9 ms, total: 641 ms\n",
      "Wall time: 187 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "116.44"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.to_feather('formats/yellow_tripdata_lz4.feather', compression='lz4')\n",
    "size_in_mb('formats/yellow_tripdata_lz4.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1e30846-28ee-4e03-8ced-e6d15402d3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 940 ms, sys: 36.9 ms, total: 977 ms\n",
      "Wall time: 216 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61.79"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.to_feather('formats/yellow_tripdata_zstd.feather', compression='zstd', compression_level=3)\n",
    "size_in_mb('formats/yellow_tripdata_zstd.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6a0e2ad-b793-4287-9d82-ad85e3f4e5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 838 ms, sys: 30.7 ms, total: 868 ms\n",
      "Wall time: 814 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59.89"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.to_parquet('formats/yellow_tripdata_snappy.parquet', \n",
    "              compression='snappy')\n",
    "size_in_mb('formats/yellow_tripdata_snappy.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "861a5296-d211-48d6-8d03-069d989a657d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 855 ms, sys: 19.6 ms, total: 875 ms\n",
      "Wall time: 795 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59.92"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.to_parquet('formats/yellow_tripdata_lz4.parquet', \n",
    "              compression='lz4')\n",
    "size_in_mb('formats/yellow_tripdata_lz4.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdc2655a-c602-4c0f-a5fe-dcdb230ec725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 899 ms, sys: 29.4 ms, total: 928 ms\n",
      "Wall time: 843 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48.95"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.to_parquet('formats/yellow_tripdata_zstd.parquet', \n",
    "              compression='zstd')\n",
    "size_in_mb('formats/yellow_tripdata_zstd.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cc7ed44-2d3d-4b38-96ba-b75f9ff0925c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('formats/yellow_tripdata_zstd', '.orc')\n",
      "('formats/yellow_tripdata_lz4', '.feather')\n",
      "('formats/yellow_tripdata_zstd', '.feather')\n",
      "('formats/yellow_tripdata_uncompressed', '.feather')\n",
      "('formats/yellow_tripdata_snappy', '.parquet')\n",
      "('formats/yellow_tripdata', '.json')\n",
      "('formats/yellow_tripdata_uncompressed', '.orc')\n",
      "('formats/yellow_tripdata', '.csv')\n",
      "('formats/yellow_tripdata_zstd', '.parquet')\n",
      "('formats/yellow_tripdata_lz4', '.parquet')\n",
      "('formats/yellow_tripdata_lz4', '.orc')\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "for filepath in glob.glob('formats/*'):\n",
    "    print(os.path.splitext(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfa3b72e-8572-4233-86ad-93f0a9f92cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "def measure_read_performance(folder_path):\n",
    "\n",
    "  performance_data = []\n",
    "  for file_path in glob.glob(f'{folder_path}/*'):\n",
    "    _, ext = os.path.splitext(file_path)\n",
    "    start_time = time.time()\n",
    "      \n",
    "    if ext == '.csv':\n",
    "      pd.read_csv(file_path, low_memory=False)\n",
    "    elif ext == '.parquet':\n",
    "      pd.read_parquet(file_path)\n",
    "    elif ext == '.feather':\n",
    "      pd.read_feather(file_path)\n",
    "    elif ext == '.orc':\n",
    "      pd.read_orc(file_path)\n",
    "    elif ext == '.json':\n",
    "      pd.read_json(file_path)\n",
    "\n",
    "    end_time = time.time()\n",
    "    performance_data.append({'filename': file_path, \n",
    "                             'read_time': end_time - start_time})\n",
    "\n",
    "    df = pd.DataFrame(performance_data)\n",
    "\n",
    "  return df.sort_values('read_time').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a752d623-2cff-4b7d-88ee-9bba75b113ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "results =\\\n",
    "    measure_read_performance(folder_path='formats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f82c5538-9b43-430c-bb61-ba4fab89045a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        filename  read_time\n",
      "0            formats/yellow_tripdata_lz4.parquet   0.070845\n",
      "1         formats/yellow_tripdata_snappy.parquet   0.072083\n",
      "2           formats/yellow_tripdata_zstd.parquet   0.078382\n",
      "3            formats/yellow_tripdata_lz4.feather   0.103172\n",
      "4           formats/yellow_tripdata_zstd.feather   0.103918\n",
      "5   formats/yellow_tripdata_uncompressed.feather   0.116974\n",
      "6               formats/yellow_tripdata_zstd.orc   0.474430\n",
      "7       formats/yellow_tripdata_uncompressed.orc   0.592284\n",
      "8                formats/yellow_tripdata_lz4.orc   0.613846\n",
      "9                    formats/yellow_tripdata.csv   4.557402\n",
      "10                  formats/yellow_tripdata.json  14.590845\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bba608-ffce-4320-aeaf-2c500b1268e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ts-1]",
   "language": "python",
   "name": "conda-env-ts-1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
